<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
        <meta name="description" content="Hidden Markov Model with Javascript">
        <meta name="keywords" content="Hidden Markov Model, HMM, Baum-Welch algorithm, EM algorithm">
        <meta name="author" content="m.zaradzki">
        
        
        <title>Importance sampling for Bayesian prediction</title>

        <!-- Bootstrap core CSS -->
        <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">
        <!-- Custom styles for this template -->
        <link href="../css/styling.css" rel="stylesheet">
        <link href="../css/favicon.ico" rel="shortcut icon">

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
        </script>
        <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <!--<p>
        When $a \ne 0$, there are two solutions to \(ax^2 + bx + c = 0\) and they are $$x = {-b \pm \sqrt{b^2-4ac} \over 2a}.$$
        </p>-->
        <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.3.0/Chart.bundle.min.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/numeric/1.2.6/numeric.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jstat/1.6.2/jstat.js"></script>

        <script type="text/javascript" src="https://www.gstatic.com/charts/loader.js"></script>

        <script>
            
            // Let the random generator run for a while
            for (var burn=0; burn<25; burn++)
            {
                Math.random();
            }

            var sigmoid = function (x) {
                return 1. / (1. + Math.exp(-x));
            }

            TrueTheta = [-1.27, -0.40, 0.83, 1.23]; // a random draw of independant N(0,1)

            var Games = []; // Observed data
            Games.push( {player1:1, player2:3, winner:null} );
            Games.push( {player1:3, player2:1, winner:null} );
            Games.push( {player1:0, player2:1, winner:null} );
            Games.push( {player1:1, player2:0, winner:null} );
            Games.push( {player1:1, player2:2, winner:null} );
            Games.push( {player1:2, player2:1, winner:null} );
            Games.push( {player1:2, player2:3, winner:null} );
            Games.push( {player1:3, player2:2, winner:null} );
            Games.push( {player1:0, player2:2, winner:null} );
            Games.push( {player1:2, player2:0, winner:null} );
            Games.push( {player1:0, player2:3, winner:null} );
            // We will estimate this LAST one :
            var newGame = {player1:3, player2:0, winner:null};

            for (var g=0; g<Games.length; g++) { // Generate face "Observed" games according to made-up probabilities
                var i = Games[g].player1;
                var j = Games[g].player2;
                var P_i_vs_j = sigmoid(TrueTheta[i] - TrueTheta[j]);

                if (Math.random()<P_i_vs_j) {
                    Games[g].winner = i;
                }
                else {
                    Games[g].winner = j;
                }
            }

            // Draw table to observed game results
            google.charts.load('current', {'packages':['table']});
            google.charts.setOnLoadCallback(drawTables);
            function drawTables() {
                drawTable1();
                drawTable2();
            }

            function drawTable1() {
                var data = new google.visualization.DataTable();
                data.addColumn('number', 'Game #');
                data.addColumn('number', 'Team 1');
                data.addColumn('number', 'Team 2');
                data.addColumn('number', 'Winner');

                var rows = [];
                for (var g=0; g<Games.length; g++) {
                    rows.push( [g+1, Games[g].player1,  Games[g].player2, Games[g].winner] );
                }
                data.addRows( rows );

                var table = new google.visualization.Table(document.getElementById('score_table_div'));
                table.draw(data, {showRowNumber: false, width: '50%', height: '100%'});
            }

            var Thetas = []; // Thetas = [Theta,...] and sigmoid(Theta[i]-Theta[j]) for each "i versus j" Bernoulli
            var Ws = [];

            var nb_simulations = 500;
            for (var k=0; k<nb_simulations; k++) // Monte Carlo
            {
                // Simulate Theta according to Prior (or, more generally, according to Q)
                var Theta = []; // TO DO
                for (var i=0; i<4; i++) {
                    Theta.push( jStat.normal.sample(0, 1) );
                }

                Thetas.push(Theta);

                var P_observations = 1.;

                for (var g=0; g<Games.length; g++) { // Observed games
                    var i = Games[g].player1;
                    var j = Games[g].player2;
                    var w = Games[g].winner;
                    var P_i_vs_j = sigmoid(Theta[i] - Theta[j]);

                    var P_game = 0;
                    if (w == i) {
                        P_game = P_i_vs_j
                    }
                    else {
                        P_game = 1 - P_i_vs_j
                    }
                    
                    P_observations *= P_game;
                }
                W = P_observations; // more generally W = P(O/theta) * Prior(theta) / Q(theta)
                Ws.push(W);
            }
            var W_sum = 0;
            for (var k=0; k<nb_simulations; k++) // Monte Carlo
            {
                W_sum += Ws[k];
            }

            var I = newGame.player1;
            var J = newGame.player2;
            var Ps = [];
            var Pred_P_I_vs_J = 0;
            for (var k=0; k<nb_simulations; k++) // Monte Carlo
            {
                // Compute the prediction here
                var Theta = Thetas[k];
                var weight = Ws[k] / W_sum;
                var P = sigmoid(Theta[I] - Theta[J]);
                Ps.push( P );
                Pred_P_I_vs_J += P * weight;
            }
            var True_P_I_vs_J = sigmoid(TrueTheta[I] - TrueTheta[J]);

            function drawTable2() {
                var data = new google.visualization.DataTable();
                data.addColumn('number', 'Game #');
                data.addColumn('number', 'Team 1');
                data.addColumn('number', 'Team 2');
                data.addColumn('number', 'True prob. 1 wins');
                data.addColumn('number', 'Pred. prob. 1 wins');

                var rows = [];
                rows.push( [12, newGame.player1,  newGame.player2, True_P_I_vs_J, Pred_P_I_vs_J] );

                data.addRows( rows );

                var table = new google.visualization.Table(document.getElementById('prediction_table_div'));
                table.draw(data, {showRowNumber: false, width: '50%', height: '100%'});
            }
            //
        </script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.17.0/vis.js"></script>
        <link href="https://cdnjs.cloudflare.com/ajax/libs/vis/4.17.0/vis.min.css" rel="stylesheet" />
        
    </head>
    <body>
        <div class="container">
        <div class="row"><div class="col-md-10 col-md-offset-1">
            <div class="row">
                <div class="page-header">
                    <h1>Importance sampling for Bayesian prediction</h1>
                    <h2><small>M.ZARADZKI - 2017</small></h2>
                </div>
                <div>
                    <h4>Application example</h4>

                    Bayesian inference and prediction is particularly suited to deal with cases where there is not a lot of data available to fit the probabilistic model of choice.<br>
                    <br>
                    As an example we can think of a sport season : as each game is played we want to refine our prediction on the future games. As a whole there are not that many games a given team will play (one per week at most) during the season, plus we want to start making forecast from the begining of the season even when only 3 games have been played.<br>
                    <br>
                    Even if 3 games is not enough to fit any model with reasonable confidence we should still make use of this data. But we use it only as a way to refine a "Prior" information that represent expert knowledge. Formally this Prior is given as a probability distribution on likely parameter values for the model.<br>
                    <br>
                </div>
            </div>
            <div class="row">
                <h4>Formal problem statement</h4>

                We have a set of observations comprising of explanatory variables and target variables :<br>
                $\mathcal{O}=\left\{ \left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right),\ldots,\left(x_{N},y_{N}\right)\right\}$
                <br><br>

                Our goal is to make a prediction on the target variable value for a new sample.<br>
                Formally we want to compute the probability :<br>
                $P\left(y^{new}\left|x^{new},\mathcal{\mathcal{O}}\right.\right)$
                <br><br>

                In a Bayesian setting we do not assume a single "best" value for $\theta$ so we integrate over its probability distribution as follow :<br>
                $P\left(y^{new}\left|x^{new},\mathcal{\mathcal{O}}\right.\right)=\int P\left(y^{new}\left|x^{new},\theta\right.\right)P\left(\theta\left|\mathcal{O}\right.\right)d\theta$
                <br><br>
            </div>
            <div class="row">
                <h4>Monte Carlo approximation</h4>

                Using Bayes formula we get :<br>
                $P\left(\theta\left|\mathcal{O}\right.\right)=\frac{P\left(\mathcal{O}\left|\theta\right.\right)Prior\left(\theta\right)}{P\left(\mathcal{O}\right)}$
                <br><br>

                The denominator can expressed as an integral :<br>
                $P\left(\mathcal{O}\right)=\int P\left(\mathcal{O}\left|\theta\right.\right)Prior\left(\theta\right)d\theta$
                <br><br>
                
                As the denominator does not depend on $\theta$ we get :<br>
                $P\left(y^{new}\left|x^{new},\mathcal{\mathcal{O}}\right.\right)=\frac{\int P\left(y^{new}\left|x^{new},\theta\right.\right)P\left(\mathcal{O}\left|\theta\right.\right)Prior\left(\theta\right)d\theta}{\int P\left(\mathcal{O}\left|\theta\right.\right)Prior\left(\theta\right)d\theta}$
                <br><br>

                We can rewrite the 2 integrals as expectations as to approximate them via Monte Carlo simulation :<br>
                $P\left(y^{new}\left|x^{new},\mathcal{\mathcal{O}}\right.\right)=\frac{E_{Prior}\left[P\left(y^{new}\left|x^{new},\theta\right.\right)P\left(\mathcal{O}\left|\theta\right.\right)\right]}{E_{Prior}\left[P\left(\mathcal{O}\left|\theta\right.\right)\right]}$
                <br><br>

                More generally we can sample from an auxialiary distribution $Q$ by setting :<br>
                $W_{Q}\left(\theta\right)=\frac{P\left(\mathcal{O}\left|\theta\right.\right)Prior\left(\theta\right)}{Q\left(\theta\right)}$
                <br><br>

                Then we get :<br>
                $P\left(y^{new}\left|x^{new},\mathcal{\mathcal{O}}\right.\right)=\frac{E_{Q}\left[P\left(y^{new}\left|x^{new},\theta\right.\right)W_{Q}\left(\theta\right)\right]}{E_{Q}\left[W_{Q}\left(\theta\right)\right]}$
                <br><br>
            </div>
            <div class="row">
                <h4>Example</h4>
                For this experiment lets consider a tennis tournament with 4 players.<br>
                The players are labelled 0,1,2,3 and their actual strength (the model need to infer it from scores) is increasing with their labels.<br>
                Lets assume the players are quite young and not well known so we have identical prior distribution on their strength ; a standard gaussian.<br>
                The strengths of each opponent are such that the probability of A winning over B is :<br>
                $P=sigmoid(strength(A) - strength(B))$.<br>
                <br>
                <h5>Observed data</h5>
                <div id="score_table_div" class="text-center"></div>
                <br>
                <h5>Bayesian Monte-Carlo Prediction Average</h5>
                <div id="prediction_table_div" class="text-center"></div>
                <br>
                <h5>Bayesian Monte-Carlo Prediction Histogram</h5>
                <div style="width:75%;" class="center-block">
                    <canvas id="myChart1"></canvas>
                </div>
                <br>
                <!--<p><b>2nd chart</b> : a posteriori density of A and B success rate</p>
                <div style="width:75%;" class="center-block">
                    <canvas id="myChart2"></canvas>
                </div>
                <br>
                <p><b>3rd chart</b> : probability to picking the best action</p>
                Here we use the running $\Theta_{a,b}$ parameters to compute $P\left(B_{b}\geq B_{a}\right)$.<br>
                Remark : There is no closed-formula for this but this is a simple 1d numerical integration.<br>
                <div style="width:75%;" class="center-block">
                    <canvas id="myChart3"></canvas>
                </div>
                <br>-->
            </div>
        </div></div>
        </div> <!-- /container -->
        <script>
            var ctx1 = document.getElementById("myChart1").getContext("2d");
            var mindex = [];
            var H1s = [];
            for (var b=0; b<10; b++) {
                mindex.push( (0.05 + b*0.10).toFixed(2) ) ;
                H1s.push( 0 );
            }
            var step = 10;
            for (var k=0; k<nb_simulations; k++) {
                var bucket = Math.floor(Ps[k]*10);
                H1s[bucket] = H1s[bucket] + Ws[k];
            }
            var myChart1 = new Chart(ctx1, {
                type: 'bar',
                data: {
                    labels: mindex,
                    datasets: [
                        {
                            label: 'XXX',
                            data: H1s,
                            backgroundColor: 'rgba(255, 90, 90, 1)',
                            borderColor: 'rgba(255, 90, 90, 0.4)',
                            fill: false,
                        },
                    ],
                },
                options: {
                    // see : http://stackoverflow.com/questions/37204298/chartjs-v2-hide-dataset-labels
                    legend: {
                        display: false
                    },
                    scales: {
                        yAxes: [{
                            ticks: {
                                beginAtZero: true
                            }
                        }]
                    },
                },
            });
        </script>
        <!--<script>
            var ctx2 = document.getElementById("myChart2").getContext("2d");
            var X = [];
            var Pa = [];
            var Pb = [];
            var i = Thetas.length-1;
            var steps = 50;
            for (var s=0; s<=steps; s++) {
                var x = s/steps;
                X.push( x );
                Pa.push( jStat.beta.pdf(x, Thetas[i][0], Thetas[i][1]) );
                Pb.push( jStat.beta.pdf(x, Thetas[i][2], Thetas[i][3]) );
            }
            var myChart2 = new Chart(ctx2, {
                type: 'line',
                data: {
                    labels: X,
                    datasets: [
                        {
                            label: 'pdf of Prob. A',
                            data: Pa,
                            backgroundColor: 'rgba(255, 90, 90, 0.5)',
                            borderColor: 'rgba(255, 90, 90, 0.5)',
                            fill: true,
                        },
                        {
                            label: 'pdf of Prob. B',
                            data: Pb,
                            backgroundColor: 'rgba(90, 255, 90, 0.5)',
                            borderColor: 'rgba(90, 255, 90, 0.5)',
                            fill: true,
                        },
                    ],
                },
                options: {
                    // see : http://stackoverflow.com/questions/37204298/chartjs-v2-hide-dataset-labels
                    legend: {
                        display: true
                    },
                    elements: { point: { radius: 0 } }, // hide "dots"
                    scales: {
                        yAxes: [{
                            ticks: {
                                beginAtZero: true
                            }
                        }]
                    },
                },
            });
        </script>
        <script>
            var ctx3 = document.getElementById("myChart3").getContext("2d");
            var mindex = [];
            var Pbest = [];
            var steps = 10;
            for (var s=0; s<Thetas.length/steps; s++) {
                var i = s*steps;
                mindex.push( i );
                var p_best = 0;
                var w_total = 0;
                for (k=1; k<25; k++) { // numerical integration
                    var x = k/25;
                    var w = jStat.beta.pdf(x, Thetas[i][0], Thetas[i][1]);
                    w_total+= w;
                    p_best+= w * ( 1-jStat.beta.cdf(x, Thetas[i][2], Thetas[i][3]) );
                }

                Pbest.push( p_best/w_total );
            }
            var myChart3 = new Chart(ctx3, {
                type: 'line',
                data: {
                    labels: mindex,
                    datasets: [
                        {
                            label: 'Prob. best choice',
                            data: Pbest,
                            backgroundColor: 'rgba(255, 90, 90, 0.5)',
                            borderColor: 'rgba(255, 90, 90, 0.5)',
                            fill: true,
                        },
                    ],
                },
                options: {
                    // see : http://stackoverflow.com/questions/37204298/chartjs-v2-hide-dataset-labels
                    legend: {
                        display: true
                    },
                    //elements: { point: { radius: 0 } }, // hide "dots"
                    scales: {
                        yAxes: [{
                            ticks: {
                                beginAtZero: true
                            }
                        }]
                    },
                },
            });
        </script>-->
    </body>
</html>